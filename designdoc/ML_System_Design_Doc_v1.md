# ML System Design Doc - [RU]
## Дизайн ML системы - BASNya MVP #1

### 0. Meta
- Разные разделы этого документа написаны от лица 2х "персонажей":
  1. Product Owner - `PO` - Nick - вымышленный дата-журналист, который с помощью python-стека анализирует статистику НБА и постит найденные интересные факты (преимущественно) в твиттер 
  2. Data Scientist - `DS` - Алексей
- MVP #1 - фактически одна большая фаза discovery и не предполагает внедрения и удобного UI
- *Сделано по Шаблону ML System Design Doc от телеграм-канала [Reliable ML](https://t.me/reliable_ml)*
- Графы нарисованы через [mermaid](https://mermaid.live/edit)
- Таблицы сконвертированы в markdown [так](https://tabletomarkdown.com/convert-spreadsheet-to-markdown/)

### 1. Цели и предпосылки 
#### 1.1. Зачем идем в разработку продукта?  

- Бизнес-цель `PO`: 

Сократить время и усилия, затрачиваемые на анализ только что закончившихся матчей и написание текста новости\твита; охватить большее количество игр, игроков и клубов
- Почему станет лучше, чем сейчас, от использования ML `PO` & `DS`: 

Уменьшение рутинных операций, уменьшение задержки между окончанием игры и выходом твита о ней, увеличение количества твитов  
- Что будем считать успехом итерации с точки зрения бизнеса `PO`: 

Скрипт, который позволяет в течение 1 часа после окончания игры НБА получить 3+ идеи для твита  

#### 1.2. Бизнес-требования и ограничения `PO`   
Текущий бизнес-процесс: 

1. дата-журналист внимательно смотрит игру и по ходу формирует гипотезы для потенциальной новости
2. после окончания игры собирает необходимые данные и проводит их анализ, проверяет гипотезы
3. формулирует текст твита на основе одной из гипотез

Базнес-процесс после окончания данной итерации:
1. после окончания игры дата-журналист запускает скрипт, который выдаёт 
    - список потенциально интересных стат. фактов 
    - вариант текста твита для каждого факта
    - доказательства правдивости этого факта
2. дата-журналист выбирает 1+ факт и готовит на его основе твит (возможно проведя доп. анализ\валидацию вручную)

* Бизнес-ограничения `PO`:
    * поддержание инфраструктуры проекта обходится меньше, чем в $50 
    * время работы скрипта - не более 1 часа
    * прозрачность того, какой именно срез исторических данных был использован для каждого факта
    * возможность выбора разреза данных: сезон НБА в целом, сезон клуба, несколько последних сезонов клуба, сезон игрока, карьера игрока

* Критерии успеха `PO`: на дистанции в 1 игровую неделю (~50 игр) применение скрипта позволяет написать 3 твита с минимальной ручной доработкой и 1 твит с доп. ручным исследованием  
 

#### 1.3. Что входит в скоуп проекта/итерации, что не входит   

* На закрытие каких БТ подписываемся в данной итерации `DS`: 
  * создание пайплайна данных
  * определение алгоритмов для выделения фактов-кандидатов
  * генерация текста твита по заданному факту
  * создание скрипта   
- Что не будет закрыто `DS`: доказательство корректности выдаваемых вариантов  
- Описание результата с точки зрения качества кода и воспроизводимости решения `DS`: код разбит на функциональные модули (сбор данных, формирование фактов-кандидатов, генерация текста), модели\алгоритмы\промпты версионируются  
- Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации) `DS`: более удобный UI, развёрнутая документация

#### 1.4. Предпосылки решения `DS`: 

**не монимаю, что тут писать, примеры разнонаправлены, надо спросить в тг\на семинаре**
- Описание всех общих предпосылок решения, используемых в системе – с обоснованием от запроса бизнеса: какие блоки данных используем, горизонт прогноза, гранулярность модели, и др. `Data Scientist`  


### 2. Методология `DS`     

#### 2.1. Постановка задачи  `DS`

- поиск аномалий (именно аномалий, не новизны)
- генеративная текстовая модель

#### 2.2. Блок-схема решения  `DS`

- Блок-схема для бейзлайна и основного MVP с ключевыми этапами решения задачи:
```mermaid
    flowchart LR
        subgraph Baseline
        direction LR
        subgraph One[Этап 1]
        direction TB
        name1["`**Сбор данных**
--сбор исторических данных
--исследование возможностей сбора разметки`"]
        end
        subgraph Two[Этап 2]
        direction TB
        name2["`**Определение списка эвристик**
--поиск и ручная кластеризация твитов по теме статистики в НБА`"]
        end
        subgraph Three[Этап 3]
        direction TB
        name3["`**Имплементация эвристик**
--создание настраимого эстиматора в fit-predict стиле`"]
        end
        subgraph Four[Этап 4]
        direction TB
        name4["`**Создание промптов**
--определение подходящих LLM
--написание промптов
--соединение их в одну цепочку`"]
        end
        subgraph Five[Этап 5]
        direction TB
        name5["`**Сборка конечного прототипа**
--создание пайплайнов обработки данных
--написание единого скрипта
--тестирование в реальных условиях`"]
        end
        One --> Two
        Two --> Three
        Three --> Four
        Four --> Five
        end

        subgraph MVP
        direction LR
        subgraph TwoMVP[Этап 2]
        direction TB
        name2_mvp["`**Сбор валидационной выборки**
--ручной отбор примеров, на которых можно считать метрики`"]
        end
        subgraph ThreeMVP[Этап 3]
        direction TB
        name3_mvp["`**Выбор алгоритмов детекции аномалий**
--подбор подходящих алгоритмов\моделей
--выбор лучшего\лучших на основе метрик`"]
        end
        end
        One --> TwoMVP
        TwoMVP --> ThreeMVP
        ThreeMVP --> Four
```

#### 2.3. Этапы решения задачи `DS`  

###### Этап 1. Сбор данных

| Название данных                                                                   | Есть ли данные в компании | Ресурс и роли\\права, нужные для получения данных | Проверено ли качество данных (да, нет) |
| --------------------------------------------------------------------------------- | ------------------------- | ------------------------------------------------- | -------------------------------------- |
| raw_games - игры НБА за последние Н сезонов                                       | нет                       | портал stats.nba.com                              | нет                                    |
| raw_players - данные об игроках за последние Н сезонов                            | нет                       | портал stats.nba.com                              | нет                                    |
| raw_play_by_plays - “ход игры” для каждой игры из raw_games                       | нет                       | портал stats.nba.com                              | нет                                    |
| raw_boxscores - стат. протокол для каждой игры из raw_games                       | нет                       | портал stats.nba.com                              | нет                                    |
| target_anomaly - стат. линейка игрока по итогам матча, которую считаем иномальной | нет                       | ручной\\полуавтоматический сбор                   | нет                                    |

Примечание: портал stats.nba.com доступен через публичный api и не требует особых прав\креденшиалов

Результат этапа: 
- исторические данные доступные на момент начала этапа загружены в raw_* таблицы 
- есть пайплайн добора данных (для только что сыгранных матчей), который можно запускать вручную
- `target_anomaly` заполняется на следующем этапе

###### Этап 2. Определение списка эвристик
Процесс: 
1. поиск подходящих источников гуглением 
2. выделение приоритетных источников (твиттеры, субреддиты) 
3. скрапинг результатов из них за последние Н лет 
4. ручная разметка на классы:
    * простая аномальная статистика игрока
    * сложная аномальная статистика игрока 
    * не релевантно текущей итерации, но может быть полезно в будущем
    * не релевантно задаче вообще
5. для всех сеплов 1го и 2го класса найти дату игры и стат. линейку игрока и сложить в `target_anomaly`
6. анализ `target_anomaly`, выделение схожих кейсов (кластеризация) и формулирование правил

**(простое требует 1го показателя, который уже есть или может быть легко рассчитан, сложное - всё остальное)**

Результат этапа: 
- описано 5+ источников необычной статистики игроков
- собрано 100+ примеров аномальной статистики игроков
- сформулировано 10+ правил-эвристик для определения "простой" аномальной статистики игроков и 5+ правиил - для "сложной" 

###### Этап 3. Имплементация эвристик
Процесс:
1. создание для каждого правила класса\функции, который по новой игре и историческим данным ищет аналогичные этому правилу аномалии 
2. приведение всех классов к единому интерфейсу
3. прогон всех классов на исторических данных (на предыдущем сезоне) и EDA полученных результатов 
4. создание эстиматора в fit-predict стиле, который объединяет настраиваемый набор из этих классов
5. определение оптимального набора на основе EDA из п.3

Результат этапа: есть класс-эстиматор, определяющий для стат. линейке игрока в "новой" игре, является она аномалией или нет 

###### Этап 2 (MVP). Сбор валидационной выборки
Процесс и желаемый результат будут понятны и определены после выполнения всех этапов линейки baseline
###### Этап 3 (MVP). Выбор алгоритмов детекции аномалий
Процесс и желаемый результат будут понятны и определены после выполнения всех этапов линейки baseline
###### Этап 4. Создание промптов

Процесс:
* написание промптов по генерации твита
  * в т.ч. с учётом БТ о прозрачности среза использованных данных
* (если необходимо) создание агентов по поиску в имеющейся БД
* соединение промптов в одну цепочку
* выбор подходящих LLM 
  * скорее всего, выбор между доступными моделями openai на основе субъективного трейдоффа цена-качество
  * или решение о необходимости файнтюна под свои нужды

Результат этапа: есть модуль, который на основе выходных результатов эстиматора генерирует текст твита 

###### Этап 5. Сборка конечного прототипа

Процесс:
- создание пайплайнов обработки данных
- написание единого скрипта
- тестирование в реальных условиях
- оценка количества сгенерированных твитов (объективная метрика), из разнообразия (метрика, которую можно формализовать) и качества (субъективная)

Результат этапа: скрипт работает в условиях приближенных к реальным
  
### 3. Подготовка пилота  `DS`
  
#### 3.1. Способ оценки пилота  
  
Пилот: 
- на промежутке в 1 неделю после каждой закончившейся игры НБА вручную запускается скрипт и сохраняются его результаты
- результаты просматриваются вручную `PO` для выделения "почти-готовых" твитов и потенциально интересных тем для доп. исследования

#### 3.2. Что считаем успешным пилотом `PO`  
1. скрипт при каждом запуске выдаёт или релевантный список фактов\твитов или сообщение о недоступности необходимых сервисов
2. среди полученных результатов есть материал для
   - 3х твитов с минимальной ручной доработкой 
   - 1 твита с доп. ручным исследованием 
#### 3.3. Подготовка пилота  

Если есть готовый скрипт и БД с историческими данными, то для подготовки пилота достаточно просто дождаться начала сезона НБА  

### 4. Внедрение     

Текущая итерация:
1. ограничевается только пилотными запусками
2. не предполагает разделения на production и не-production системы

Поэтому этот раздел не нужен

