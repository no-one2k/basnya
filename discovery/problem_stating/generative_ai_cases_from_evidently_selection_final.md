| #  | компания                                                       | что делали                                                                                                                                                                                                                                                                                                                                                                       | как оценивали результат                                                                                                                                      | как делали разметку                                                                                                                 | как боролись с галюцинациями\\багами                                                                                                                                   | ссылка                                                                                                                    |
| -- | -------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- |
| 1  | stich fix<br>Маркетплейс одежды                                | \- we map the outfit and a set of style keywords to the latent style space<br>\- and then find the style keywords closest to the outfit in that space.<br>\- Next, we use GPT-3 to generate headlines based on the selected style keywords (few-shot learning).<br>\- Our human experts (copywriters) then review and edit the headlines generated by AI                         | через эксперта, который просматривает все результаты                                                                                                         | похоже, что без разметки                                                                                                            | через эксперта                                                                                                                                                         | https://multithreaded.stitchfix.com/blog/2023/03/06/expert-in-the-loop-generative-ai-at-stitch-fix/                       |
| 2  | stich fix<br>Маркетплейс одежды                                | \- we gathered a task-specific dataset<br>\- human experts write several hundred high-quality product descriptions (the “completion”, or training output)<br>based on product attributes (the “prompt”, or training input).<br>\- We then fine-tuned the base model                                                                                                              | субъективно                                                                                                                                                  | посадили людей писать 100-1000 описаний товара (Y) по его набору свойств (X)                                                        |                                                                                                                                                                        | https://multithreaded.stitchfix.com/blog/2023/03/06/expert-in-the-loop-generative-ai-at-stitch-fix/                       |
| 3  | Microsoft<br>Отдел по устранению инфраструктурных инцидентов   | \- собрали ист. датасет из описания тикета (Х) и установленной причины инцидента (У)<br>\- прогнали на них гпт-3 и гпт3.5 в режиме зеро-шот<br>\- зафайнтюнили гпт3.5 на части датасета<br>\- лучше всего перфоррмит файн-тьюн версия                                                                                                                                            | \- лексические метрики (bleu и проч.) между У и выходом модели<br>\- опрос авторов тикетов о том, нравится ли им ответ по 5-бальной шкале                    | взяли из БД инцидентов                                                                                                              | \-                                                                                                                                                                     | https://www.microsoft.com/en-us/research/blog/large-language-models-for-automatic-cloud-incident-management/              |
| 4  | Microsoft<br>Отдел по устранению инфраструктурных инцидентов   | что хотят попробовать:<br>вместо регулярных файнтьюнов сдлеать Retriever, который<br>\- ищет в БД похожие кейсы<br>\- ищет по документации советы и гайды<br><br>И на вход ЛЛМ подавать выход ретривера и описание тикета                                                                                                                                                        |                                                                                                                                                              |                                                                                                                                     |                                                                                                                                                                        | https://www.microsoft.com/en-us/research/blog/large-language-models-for-automatic-cloud-incident-management/              |
| 5  | GitHub Copilot                                                 | \- зафайнтюнили гпт3 на куче кода<br>\- итеративно улучшали промпты                                                                                                                                                                                                                                                                                                              | 1) на отобранном руками датасете смотрели, дополняет ли модель код правильно или нет<br>2) прокси-метрика: как часто юзеры принимают или отклоняют подсказку | никак, просто пихали в модель кучу кода по аналогии с обычным языком                                                                | модель предлагала для C# конструкции из python:<br>1) добавили в промпт название языка программирования<br>2) при файнтюне добавляли к файлу его название и расширение | https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/                                 |
| 6  | Honeycomb.io<br>Тула для аналитики работы сервисов и продуктов | Фактически делали text2sql :<br>\- пихали на вход гпт схему данных, текстовый запрос юзера, и несколько примеров<br>\- пытались обойти лимит токенов через итерационный вызов ЛЛМ и эмбеддинги<br>\- экспериментировали с промптами, чтобы добиться устойчивости и скорости работы                                                                                               | не говорят явно<br>в статье только субъективные оценки<br>+<br>процент получившихся валидных запросов (sql-like)                                             | не говорят явно                                                                                                                     | тюнили промпты                                                                                                                                                         | https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm                                                           |
| 7  | Google<br>проект по суммаризации текстов                       | \- fine-tuned our model on a corpus of documents with manually-generated summaries<br>\- cleaned and filtered (10k -> 1k) the fine-tuning data to contain training examples that were more consistent<br>\- used knowledge distillation: large model -> smaller more efficient model                                                                                             | не говорят явно<br>В статье только субъективные оценки                                                                                                       | сначала надёргали доступные пары документ-саммари, где саммари написано человеком<br>потом руками(?!) сильно проредили этот датасет | почистили датасет<br>(см. dataset distillation)                                                                                                                        | https://blog.research.google/2022/03/auto-generated-summaries-in-google-docs.html                                         |
| 8  | Google<br>проект по суммаризации диалогов                      | \- собрали спец. датасет на основе диа- и поли- логов<br>\- файнтьюнили ЛЛМ<br>\- дистиллировали её для продакшена                                                                                                                                                                                                                                                               | не говорят явно<br>В статье только субъективные оценки<br>+<br>упоминание user feedback                                                                      | собрали датасет диалогов<br>запрягли людей писать к ним саммари                                                                     | \- жёстко переформатировали датасет, чтобы модель не путала что и какой юзер сказал в диалоге                                                                          | https://blog.research.google/2022/11/conversation-summaries-in-google-chat.html                                           |
| 9  | Grammarly<br>генерация подсказок по редактированию текста      | статья вообще не про ml, ds и ai                                                                                                                                                                                                                                                                                                                                                 |                                                                                                                                                              |                                                                                                                                     |                                                                                                                                                                        | https://www.grammarly.com/blog/engineering/how-suggestions-work-grammarly-editor/                                         |
| 10 | Grammarly<br>генерация подсказок по редактированию текста      | \- для скорости сменили постановку задачи с machine translation на Sequence-tagging<br>\- для скорости сознательно ограничили количество тегов<br>\- собрали модель на основе предобученного bert'а<br>\- сначала учили на синтетике<br>\- потом файнтьюнили на собранном датасете в 2 этапа<br>(на втором этапе было много примеров, не нуждающихся в корректировке)            | по публичным бенчмаркам для задачи исправления текстов<br>+<br>сравнивали скорость инеференса с machine translation подходом                                 | \- сгенерировали огромное количество синтетики<br>\- собрали (видимо из своих ист. данных) датасет студентов                        | не было таких проблем, т.к. по сути использовалась не ЛЛМ, а негенеративная модель                                                                                     | https://www.grammarly.com/blog/engineering/gec-tag-not-rewrite/                                                           |
| 11 | AirBnB<br>проект автоматизации customer support                | \- подавали на вход запрос юзера и 1 статью из своей базы знаний<br>\- промптом просили ответить, релевантна ли статья (т.е. только да\\нет)<br>\- в такой постановке зафайнтьюнили MT5                                                                                                                                                                                          | метрики для классификации, посчитатнные на тестовом датасете<br>+<br>АБ-тест работы на проде                                                                 | взяли исторические данные о том как люди-саппортеры общались с клиентами                                                            | не было таких проблем, т.к. свели к классификации                                                                                                                      | https://medium.com/airbnb-engineering/how-ai-text-generation-models-are-reshaping-customer-support-at-airbnb-a851db0b4fa3 |
| 12 | AirBnB<br>проект автоматизации customer support                | \- отобрали типы вопросов, ответы на которые саппортеры выделяют в тексте обращения<br>\- зафайнтьюнили модель для Question-Answer общения, но только для этих вопросов<br>\- для каждого вопроса считали классификационные метрики                                                                                                                                              | метрики для классификации, посчитатнные на тестовом датасете                                                                                                 | взяли исторические данные о том как люди-саппортеры общались с клиентами                                                            | не было таких проблем, т.к. свели к классификации                                                                                                                      | https://medium.com/airbnb-engineering/how-ai-text-generation-models-are-reshaping-customer-support-at-airbnb-a851db0b4fa3 |
| 13 | AirBnB<br>проект автоматизации customer support                | \- из всей истории общения с клиентами на основе простой регулярки отобрали те семплы, где саппортер пытыается перефразировать запрос клиента<br>\- кластризовали все парафразы, глазами просмотрели все кластеры и удалили те кластеры, которые содержали слишком общие и неполезные сообщения<br>\- файнтьюнили T5 модель на парах (запрос клиента) - (парафраз от суппортера) | не говорят явно<br>скорее всего как-то субъективно                                                                                                           | хитро фильтровали историческую выборку                                                                                              | заморочились с очисткой датасета                                                                                                                                       | https://medium.com/airbnb-engineering/how-ai-text-generation-models-are-reshaping-customer-support-at-airbnb-a851db0b4fa3 |
| 14 | Google<br>проект корректировки текста на мобилке               | \- наскраппили фраз из интернета<br>\- прогнали их через большую модель для корректировки<br>\- на получившемся датасете тренировали с 0 маленькую модель                                                                                                                                                                                                                        | не говорят явно<br>скорее всего сравнивали выходы маленькой и большой модели                                                                                 | \- использовали публичные данные<br>\- прогнали их через существующую модель                                                        | проблема с постепенным вводом текста: эвристически определяли, в какой момент разумно делать корректировку и показывать её пользователю                                | https://blog.research.google/2021/10/grammar-correction-as-you-type-on-pixel.html                                         |
| 15 | Grammarly<br>генерация подсказок по редактированию текста      | статья про то, как они свели поиск ошибок в тексте к работе GAN’а<br>нам не очень релевантно                                                                                                                                                                                                                                                                                     |                                                                                                                                                              |                                                                                                                                     |                                                                                                                                                                        | https://www.grammarly.com/blog/engineering/adversarial-grammatical-error-correction/                                      |